{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Leibniz-Clarke Letters-NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPV3QUM2RInWlsvP2bp3XJv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCoreMan13/NLP-Leibniz-Clarke-Letters/blob/main/Leibniz_Clarke_Letters_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPhucM6fA6mO"
      },
      "source": [
        "# **Modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rynTrUZR6jE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96439da9-a9cf-4553-a62f-840b2531f988"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdNjY0jQ6l07"
      },
      "source": [
        "# **Import Leibniz-Clarke Letters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pJ6mjzZTr3x"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "tree = ET.parse('/content/Leibniz-Clarke Letters.xml')\n",
        "root = tree.getroot()\n",
        "\n",
        "#Transform the letter in string\n",
        "df = ET.tostring(root, encoding='utf8').decode('utf8')\n",
        "# print(df)\n",
        "\n",
        "\n",
        "final_tokens = word_tokenize(df)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuRRmWrL7vij"
      },
      "source": [
        "# **POS (Parts Of Speech) settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttph9WJgnnPh"
      },
      "source": [
        "# Constants\n",
        "# POS (Parts Of Speech) for: nouns, adjectives, verbs and adverbs\n",
        "DI_POS_TYPES = {'NN':'n', 'JJ':'a', 'VB':'v', 'RB':'r'} \n",
        "POS_TYPES = list(DI_POS_TYPES.keys())\n",
        "\n",
        "# Constraints on tokens\n",
        "MIN_STR_LEN = 3\n",
        "RE_VALID = '[a-zA-Z]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O74hdy3f7Xhj"
      },
      "source": [
        "# **Remove stopwords, Tokenize sentences and words, use stemmer & lemmatizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G8Ao9KR1jZ-"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "# Get stopwords, stemmer and lemmatizer\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "stopwords.append('utterance')\n",
        "stopwords.append('ref')\n",
        "stopwords.append('genid')\n",
        "stopwords.append ('clarke')\n",
        "stopwords.append ('thing')\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "print(df)\n",
        "# Remove accents function\n",
        "def remove_accents(data):\n",
        "    return ''.join(x for x in unicodedata.normalize('NFKD', data) if x in string.ascii_letters or x == \" \")\n",
        "\n",
        "# Process all quotes\n",
        "li_tokens = []\n",
        "li_token_lists = []\n",
        "li_lem_strings = []\n",
        "\n",
        "for i,text in enumerate(final_tokens):\n",
        "    # Tokenize by sentence, then by lowercase word\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "\n",
        "    # Process all tokens per quote\n",
        "    li_tokens_quote = []\n",
        "    li_tokens_quote_lem = []\n",
        "    for token in tokens:\n",
        "        # Remove accents\n",
        "        t = remove_accents(token)\n",
        "\n",
        "        # Remove punctuation\n",
        "        t = str(t).translate(string.punctuation)\n",
        "        li_tokens_quote.append(t)\n",
        "        \n",
        "        # Add token that represents \"no lemmatization match\"\n",
        "        li_tokens_quote_lem.append(\"-\") # this token will be removed if a lemmatization match is found below\n",
        "\n",
        "        # Process each token\n",
        "        if t not in stopwords:\n",
        "            if re.search(RE_VALID, t):\n",
        "                if len(t) >= MIN_STR_LEN:\n",
        "                    pos = nltk.pos_tag([t])[0][1][:2]\n",
        "                    pos2 = 'n'  # set default to noun\n",
        "                    if pos in DI_POS_TYPES:\n",
        "                      pos2 = DI_POS_TYPES[pos]\n",
        "                    \n",
        "                    stem = stemmer.stem(t)\n",
        "                    lem = lemmatizer.lemmatize(t, pos=pos2)  # lemmatize with the correct POS\n",
        "                    \n",
        "                    if pos in POS_TYPES:\n",
        "                        li_tokens.append((t, stem, lem, pos))\n",
        "\n",
        "                        # Remove the \"-\" token and append the lemmatization match\n",
        "                        li_tokens_quote_lem = li_tokens_quote_lem[:-1] \n",
        "                        li_tokens_quote_lem.append(lem)\n",
        "\n",
        "    # Build list of token lists from lemmatized tokens\n",
        "    li_token_lists.append(li_tokens_quote)\n",
        "    \n",
        "    # Build list of strings from lemmatized tokens\n",
        "    str_li_tokens_quote_lem = ' '.join(li_tokens_quote_lem)\n",
        "    li_lem_strings.append(str_li_tokens_quote_lem)\n",
        "    \n",
        "# Build resulting dataframes from lists\n",
        "df_token_lists = pd.DataFrame(li_token_lists)\n",
        "\n",
        "\n",
        "# Replace None with empty string\n",
        "for c in df_token_lists:\n",
        "    if str(df_token_lists[c].dtype) in ('object', 'string_', 'unicode_'):\n",
        "        df_token_lists[c].fillna(value='', inplace=True)\n",
        "\n",
        "df_lem_strings = pd.DataFrame(li_lem_strings, columns=['lem quote'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlwrxzj4ebx4"
      },
      "source": [
        "## Find the most popular concepts and group results by Part of Speech (POS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRCNR430sAOz",
        "outputId": "ce03ee2a-e61d-459c-a617-4285e0026cbd"
      },
      "source": [
        "df_all_words = pd.DataFrame(li_tokens, columns=['token', 'stem', 'lem', 'pos'])\n",
        "df_all_words['counts'] = df_all_words.groupby(['lem'])['lem'].transform('count')\n",
        "df_all_words = df_all_words.sort_values(by=['counts', 'lem'], ascending=[False, True]).reset_index()\n",
        "\n",
        "df_words = df_all_words.groupby('lem').first().sort_values(by='counts', ascending=False).reset_index()\n",
        "print(\"df_words.head(7):\")\n",
        "print(df_words.head(7))\n",
        "print(len((df_words)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_words.head(7):\n",
            "      lem  index      token    stem pos  counts\n",
            "0     god     39        god     god  NN     206\n",
            "1   space     51      space   space  NN     142\n",
            "2   thing     56     things   thing  NN     119\n",
            "3    body     16       body    bodi  NN      80\n",
            "4  reason    417  reasoning  reason  VB      74\n",
            "5  matter     36     matter  matter  NN      72\n",
            "6   world    110      world   world  NN      69\n",
            "1398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV1LUFHZW_fp"
      },
      "source": [
        "## Top 7 words per Part Of Speech (POS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyRzEMCIsTbu",
        "outputId": "2e285610-f94c-41b8-e1cd-af47830e62df"
      },
      "source": [
        "df_words = df_words[['lem', 'pos', 'counts']].head(200)\n",
        "for v in POS_TYPES:\n",
        "    df_pos = df_words[df_words['pos'] == v]\n",
        "    print()\n",
        "    print(\"POS_TYPE:\", v)\n",
        "    print(df_pos.head(7).to_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "POS_TYPE: NN\n",
            "      lem pos  counts\n",
            "0     god  NN     206\n",
            "1   space  NN     142\n",
            "2   thing  NN     119\n",
            "3    body  NN      80\n",
            "5  matter  NN      72\n",
            "6   world  NN      69\n",
            "7    soul  NN      56\n",
            "\n",
            "POS_TYPE: JJ\n",
            "             lem pos  counts\n",
            "30          real  JJ      28\n",
            "33         empty  JJ      27\n",
            "42       natural  JJ      22\n",
            "52  mathematical  JJ      20\n",
            "54          much  JJ      20\n",
            "64          true  JJ      17\n",
            "66       eternal  JJ      17\n",
            "\n",
            "POS_TYPE: VB\n",
            "       lem pos  counts\n",
            "4   reason  VB      74\n",
            "8     make  VB      55\n",
            "10     say  VB      52\n",
            "20    move  VB      36\n",
            "25    give  VB      33\n",
            "51   point  VB      20\n",
            "60    take  VB      19\n",
            "\n",
            "POS_TYPE: RB\n",
            "          lem pos  counts\n",
            "31       mere  RB      27\n",
            "34     rather  RB      27\n",
            "35       even  RB      26\n",
            "50       also  RB      21\n",
            "58       well  RB      19\n",
            "59    exactly  RB      19\n",
            "70  perfectly  RB      16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LnOHCX7u4zK"
      },
      "source": [
        "# **Frequency plot for concepts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "Ka5H6x7ishdE",
        "outputId": "78e2d2a1-c351-4a6e-a948-2f43cb9d90ab"
      },
      "source": [
        "li_lem_words = df_all_words['lem'].tolist()\n",
        "di_freq2 = nltk.FreqDist(li_lem_words)\n",
        "li_freq_sorted2 = sorted(di_freq2.items(), key=lambda x: x[1], reverse=True)  # sorted list\n",
        "print(li_freq_sorted2)\n",
        "    \n",
        "di_freq2.plot(7, cumulative=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('god', 206), ('space', 142), ('thing', 119), ('body', 80), ('reason', 74), ('matter', 72), ('world', 69), ('soul', 56), ('make', 55), ('part', 53), ('say', 52), ('present', 47), ('time', 47), ('act', 45), ('order', 45), ('principle', 44), ('leibniz', 43), ('place', 41), ('create', 39), ('power', 38), ('move', 36), ('way', 36), ('nature', 35), ('give', 33), ('motion', 33), ('nothing', 33), ('something', 31), ('show', 29), ('anything', 28), ('mean', 28), ('real', 28), ('empty', 27), ('mere', 27), ('miracle', 27), ('rather', 27), ('even', 26), ('newton', 26), ('argument', 25), ('force', 24), ('see', 24), ('sufficient', 23), ('universe', 23), ('everything', 22), ('infinite', 22), ('machine', 22), ('natural', 22), ('need', 22), ('page', 22), ('substance', 22), ('also', 21), ('exist', 21), ('mathematical', 20), ('much', 20), ('point', 20), ('sensorium', 20), ('suppose', 20), ('turn', 20), ('exactly', 19), ('take', 19), ('well', 19), ('wisdom', 19), ('go', 18), ('work', 18), ('case', 17), ('choose', 17), ('different', 17), ('eternal', 17), ('explain', 17), ('state', 17), ('true', 17), ('always', 16), ('follow', 16), ('perfectly', 16), ('alike', 15), ('great', 15), ('idea', 15), ('material', 15), ('presence', 15), ('sense', 15), ('think', 15), ('use', 15), ('absolute', 14), ('absolutely', 14), ('answer', 14), ('cause', 14), ('effect', 14), ('word', 14), ('call', 13), ('difference', 13), ('example', 13), ('get', 13), ('good', 13), ('indifferent', 13), ('man', 13), ('perfect', 13), ('perfection', 13), ('put', 13), ('wrong', 13), ('actually', 12), ('animal', 12), ('fact', 12), ('finite', 12), ('hold', 12), ('image', 12), ('know', 12), ('many', 12), ('merely', 12), ('mind', 12), ('option', 12), ('organ', 12), ('philosophy', 12), ('really', 12), ('right', 12), ('amount', 11), ('atom', 11), ('choice', 11), ('contradiction', 11), ('indeed', 11), ('notion', 11), ('omnipresent', 11), ('property', 11), ('quantity', 11), ('regard', 11), ('situation', 11), ('enough', 10), ('human', 10), ('imply', 10), ('impossible', 10), ('men', 10), ('never', 10), ('perceive', 10), ('perceives', 10), ('question', 10), ('supernatural', 10), ('weight', 10), ('whole', 10), ('accord', 9), ('argue', 9), ('aware', 9), ('contrary', 9), ('depend', 9), ('duration', 9), ('equal', 9), ('event', 9), ('existence', 9), ('external', 9), ('fix', 9), ('immediately', 9), ('meaning', 9), ('necessity', 9), ('new', 9), ('nickname', 9), ('possibly', 9), ('properly', 9), ('seem', 9), ('view', 9), ('agent', 8), ('brain', 8), ('change', 8), ('continually', 8), ('course', 8), ('eternity', 8), ('exercise', 8), ('form', 8), ('imaginary', 8), ('indiscernible', 8), ('influence', 8), ('king', 8), ('occur', 8), ('opinion', 8), ('paper', 8), ('people', 8), ('phrase', 8), ('possible', 8), ('produce', 8), ('reality', 8), ('region', 8), ('sensation', 8), ('size', 8), ('solid', 8), ('stop', 8), ('supposition', 8), ('term', 8), ('want', 8), ('watch', 8), ('yet', 8), ('begin', 7), ('continue', 7), ('disorder', 7), ('exists', 7), ('goclenius', 7), ('happens', 7), ('help', 7), ('lack', 7), ('less', 7), ('location', 7), ('maintain', 7), ('materialist', 7), ('metaphysical', 7), ('name', 7), ('namely', 7), ('otherwise', 7), ('particle', 7), ('prove', 7), ('provide', 7), ('relative', 7), ('run', 7), ('set', 7), ('sooner', 7), ('water', 7), ('active', 6), ('add', 6), ('anyone', 6), ('balance', 6), ('base', 6), ('being', 6), ('bring', 6), ('clock', 6), ('consequence', 6), ('dictionary', 6), ('else', 6), ('everywhere', 6), ('fate', 6), ('fiction', 6), ('find', 6), ('first', 6), ('idol', 6), ('immensity', 6), ('indivisible', 6), ('infinity', 6), ('intelligentia', 6), ('kind', 6), ('law', 6), ('limited', 6), ('mend', 6), ('opposite', 6), ('particular', 6), ('philosopher', 6), ('picture', 6), ('pore', 6), ('remedy', 6), ('reply', 6), ('simply', 6), ('someone', 6), ('standpoint', 6), ('subject', 6), ('try', 6), ('understood', 6), ('usual', 6), ('vacuum', 6), ('whereas', 6), ('write', 6), ('action', 5), ('advance', 5), ('already', 5), ('attribute', 5), ('believe', 5), ('certain', 5), ('continual', 5), ('design', 5), ('differ', 5), ('drop', 5), ('entire', 5), ('entirely', 5), ('etc', 5), ('ever', 5), ('false', 5), ('fill', 5), ('general', 5), ('government', 5), ('governor', 5), ('implies', 5), ('independent', 5), ('initial', 5), ('kingdom', 5), ('lead', 5), ('level', 5), ('line', 5), ('little', 5), ('mechanical', 5), ('necessarily', 5), ('necessary', 5), ('object', 5), ('operation', 5), ('others', 5), ('preserve', 5), ('prof', 5), ('proof', 5), ('quite', 5), ('resistance', 5), ('similarly', 5), ('still', 5), ('supposes', 5), ('supramundana', 5), ('therefore', 5), ('thus', 5), ('workman', 5), ('ability', 4), ('absence', 4), ('author', 4), ('away', 4), ('back', 4), ('best', 4), ('blind', 4), ('carry', 4), ('come', 4), ('compose', 4), ('concern', 4), ('consist', 4), ('constitution', 4), ('contains', 4), ('creation', 4), ('demonstrate', 4), ('discuss', 4), ('divide', 4), ('divisible', 4), ('equally', 4), ('essentially', 4), ('exclude', 4), ('fall', 4), ('far', 4), ('fatality', 4), ('fit', 4), ('flaw', 4), ('happen', 4), ('hypothesis', 4), ('immediate', 4), ('imperfect', 4), ('intelligence', 4), ('keep', 4), ('last', 4), ('lessen', 4), ('living', 4), ('long', 4), ('lose', 4), ('manifest', 4), ('mathematics', 4), ('metaphysics', 4), ('miraculous', 4), ('movement', 4), ('naturally', 4), ('next', 4), ('number', 4), ('outset', 4), ('perception', 4), ('perform', 4), ('philosophical', 4), ('physical', 4), ('preestablished', 4), ('problem', 4), ('proportion', 4), ('providence', 4), ('reduce', 4), ('relation', 4), ('require', 4), ('rest', 4), ('second', 4), ('shape', 4), ('source', 4), ('spatial', 4), ('subdivide', 4), ('sun', 4), ('switch', 4), ('system', 4), ('thesis', 4), ('thought', 4), ('together', 4), ('workmanship', 4), ('accept', 3), ('accepted', 3), ('accordance', 3), ('agree', 3), ('alter', 3), ('amendment', 3), ('arise', 3), ('arises', 3), ('assemble', 3), ('assertion', 3), ('attract', 3), ('avoid', 3), ('axiom', 3), ('bound', 3), ('capable', 3), ('care', 3), ('chance', 3), ('chose', 3), ('claim', 3), ('clockmaker', 3), ('comparison', 3), ('complex', 3), ('conflict', 3), ('conserve', 3), ('consider', 3), ('corpuscle', 3), ('creates', 3), ('decrease', 3), ('definition', 3), ('demonstration', 3), ('deny', 3), ('diffuse', 3), ('distance', 3), ('divine', 3), ('do', 3), ('earlier', 3), ('easy', 3), ('end', 3), ('epicurean', 3), ('epicurus', 3), ('error', 3), ('exact', 3), ('extend', 3), ('extension', 3), ('extraordinary', 3), ('fault', 3), ('finely', 3), ('foresight', 3), ('fourth', 3), ('freely', 3), ('friend', 3), ('full', 3), ('geometry', 3), ('goodness', 3), ('hard', 3), ('harmony', 3), ('imagination', 3), ('imagine', 3), ('include', 3), ('infinitely', 3), ('internal', 3), ('intervention', 3), ('invisible', 3), ('involve', 3), ('involves', 3), ('knowledge', 3), ('later', 3), ('let', 3), ('locate', 3), ('locke', 3), ('lord', 3), ('maker', 3), ('manner', 3), ('meant', 3), ('meet', 3), ('motif', 3), ('offer', 3), ('often', 3), ('omnipresence', 3), ('one', 3), ('passage', 3), ('person', 3), ('plainly', 3), ('pleased', 3), ('position', 3), ('purely', 3), ('regular', 3), ('regularly', 3), ('regulation', 3), ('reject', 3), ('relate', 3), ('remains', 3), ('repair', 3), ('repeat', 3), ('respect', 3), ('rotate', 3), ('scapula', 3), ('senseorgans', 3), ('ship', 3), ('side', 3), ('signify', 3), ('simple', 3), ('situate', 3), ('skill', 3), ('solar', 3), ('spontaneous', 3), ('spread', 3), ('straight', 3), ('substantially', 3), ('successive', 3), ('sufficiently', 3), ('supernaturally', 3), ('sure', 3), ('talk', 3), ('theodicy', 3), ('theologian', 3), ('tribe', 3), ('understand', 3), ('uniform', 3), ('union', 3), ('void', 3), ('vulgar', 3), ('year', 3), ('absurd', 2), ('activity', 2), ('actual', 2), ('adjust', 2), ('admit', 2), ('adversary', 2), ('affair', 2), ('age', 2), ('aim', 2), ('air', 2), ('allow', 2), ('alone', 2), ('altogether', 2), ('ancient', 2), ('angel', 2), ('appeal', 2), ('apply', 2), ('arbitrary', 2), ('archimedes', 2), ('argues', 2), ('arithmetic', 2), ('ascribe', 2), ('automatically', 2), ('bad', 2), ('beauty', 2), ('becomes', 2), ('bit', 2), ('bodily', 2), ('book', 2), ('brings', 2), ('brought', 2), ('buy', 2), ('certainly', 2), ('chief', 2), ('chooses', 2), ('circle', 2), ('cite', 2), ('common', 2), ('complete', 2), ('compound', 2), ('conceptually', 2), ('consequently', 2), ('consists', 2), ('contend', 2), ('context', 2), ('contradictory', 2), ('contrast', 2), ('conveyed', 2), ('correspondence', 2), ('count', 2), ('creator', 2), ('creature', 2), ('credit', 2), ('criticize', 2), ('cube', 2), ('curve', 2), ('day', 2), ('defect', 2), ('democritus', 2), ('dependence', 2), ('dependent', 2), ('destroy', 2), ('detect', 2), ('determine', 2), ('detracts', 2), ('develop', 2), ('dialog', 2), ('dimension', 2), ('directly', 2), ('discern', 2), ('discerns', 2), ('discussion', 2), ('disposition', 2), ('distinct', 2), ('distinction', 2), ('distinguish', 2), ('ear', 2), ('earth', 2), ('enemy', 2), ('england', 2), ('est', 2), ('establish', 2), ('exceeds', 2), ('excellence', 2), ('explanation', 2), ('explicit', 2), ('explicitly', 2), ('extent', 2), ('eye', 2), ('fancy', 2), ('felt', 2), ('figure', 2), ('final', 2), ('finites', 2), ('fluid', 2), ('follower', 2), ('foresee', 2), ('found', 2), ('garden', 2), ('glory', 2), ('governs', 2), ('grant', 2), ('grasp', 2), ('greatly', 2), ('greek', 2), ('however', 2), ('identity', 2), ('immaterial', 2), ('immense', 2), ('immovable', 2), ('impactmechanics', 2), ('imperfection', 2), ('improperly', 2), ('inanimate', 2), ('inconsiderable', 2), ('indirectly', 2), ('indistinguishable', 2), ('individual', 2), ('instead', 2), ('intelligent', 2), ('intermediate', 2), ('intrinsically', 2), ('irrelevant', 2), ('jar', 2), ('june', 2), ('lay', 2), ('layout', 2), ('leaf', 2), ('length', 2), ('like', 2), ('limit', 2), ('lipservice', 2), ('longer', 2), ('look', 2), ('materialism', 2), ('meme', 2), ('million', 2), ('miraclewhether', 2), ('mixture', 2), ('moment', 2), ('movable', 2), ('nerve', 2), ('november', 2), ('obvious', 2), ('obviously', 2), ('occurs', 2), ('optic', 2), ('pair', 2), ('par', 2), ('participant', 2), ('partition', 2), ('partly', 2), ('passive', 2), ('pattern', 2), ('perhaps', 2), ('perpetual', 2), ('planet', 2), ('premise', 2), ('prevent', 2), ('princess', 2), ('principia', 2), ('proper', 2), ('quon', 2), ('quote', 2), ('ratio', 2), ('reach', 2), ('refers', 2), ('religion', 2), ('remark', 2), ('representation', 2), ('representative', 2), ('resides', 2), ('rightly', 2), ('rule', 2), ('scholium', 2), ('scope', 2), ('section', 2), ('sens', 2), ('servant', 2), ('setup', 2), ('several', 2), ('shove', 2), ('single', 2), ('small', 2), ('socalled', 2), ('socinian', 2), ('sometimes', 2), ('sound', 2), ('specie', 2), ('spring', 2), ('start', 2), ('statement', 2), ('story', 2), ('stretch', 2), ('strongly', 2), ('stuck', 2), ('succession', 2), ('supramundane', 2), ('tangent', 2), ('technical', 2), ('tell', 2), ('tend', 2), ('theological', 2), ('third', 2), ('topic', 2), ('translate', 2), ('translates', 2), ('trouble', 2), ('unaided', 2), ('unchangeable', 2), ('uniformity', 2), ('unusual', 2), ('unworthy', 2), ('usually', 2), ('various', 2), ('virtue', 2), ('walk', 2), ('wise', 2), ('wonderful', 2), ('writer', 2), ('abc', 1), ('able', 1), ('abruptly', 1), ('absurdity', 1), ('absurdum', 1), ('abundantly', 1), ('accompany', 1), ('acknowledge', 1), ('actuality', 1), ('adapts', 1), ('additional', 1), ('adequately', 1), ('admits', 1), ('advantage', 1), ('adversaires', 1), ('affect', 1), ('afraid', 1), ('agrees', 1), ('alikeness', 1), ('allwise', 1), ('amend', 1), ('amongst', 1), ('amountofmatter', 1), ('animate', 1), ('annihilate', 1), ('anothereither', 1), ('anythingall', 1), ('anywhere', 1), ('apart', 1), ('ape', 1), ('appear', 1), ('appelle', 1), ('appendix', 1), ('applies', 1), ('appoint', 1), ('apt', 1), ('arbitrarily', 1), ('areagain', 1), ('arisen', 1), ('aristotle', 1), ('arm', 1), ('arranges', 1), ('arrive', 1), ('artisan', 1), ('aside', 1), ('ask', 1), ('asks', 1), ('assert', 1), ('assertionwhich', 1), ('assignable', 1), ('astound', 1), ('attend', 1), ('attraction', 1), ('attri', 1), ('attributesnamely', 1), ('augment', 1), ('avail', 1), ('awkward', 1), ('bacon', 1), ('barbarism', 1), ('bare', 1), ('basic', 1), ('basically', 1), ('basis', 1), ('bear', 1), ('beautiful', 1), ('become', 1), ('beginning', 1), ('big', 1), ('birth', 1), ('blindly', 1), ('block', 1), ('bodyrelated', 1), ('bottom', 1), ('bought', 1), ('boundaried', 1), ('boy', 1), ('bulk', 1), ('bute', 1), ('buyer', 1), ('cabin', 1), ('calledwhich', 1), ('carelessly', 1), ('cartesian', 1), ('caselike', 1), ('causal', 1), ('causesfor', 1), ('cave', 1), ('central', 1), ('centre', 1), ('cet', 1), ('challenged', 1), ('chimera', 1), ('chimerical', 1), ('chosen', 1), ('christian', 1), ('chronology', 1), ('circulate', 1), ('claimed', 1), ('clash', 1), ('clean', 1), ('clearer', 1), ('clearly', 1), ('clockmakerthat', 1), ('clumsier', 1), ('coexist', 1), ('coexistence', 1), ('collision', 1), ('combination', 1), ('command', 1), ('commend', 1), ('commonly', 1), ('compare', 1), ('completely', 1), ('concedes', 1), ('conceive', 1), ('concept', 1), ('conception', 1), ('concerned', 1), ('conclusion', 1), ('conclusive', 1), ('conclusively', 1), ('confine', 1), ('confirms', 1), ('conform', 1), ('conformity', 1), ('confront', 1), ('confuse', 1), ('confusion', 1), ('confute', 1), ('connect', 1), ('connection', 1), ('consequent', 1), ('conservation', 1), ('consideration', 1), ('constantly', 1), ('construct', 1), ('contain', 1), ('contends', 1), ('contingent', 1), ('continuance', 1), ('continuation', 1), ('contribute', 1), ('convey', 1), ('convince', 1), ('corporeal', 1), ('correction', 1), ('correspond', 1), ('corrupt', 1), ('countless', 1), ('country', 1), ('cover', 1), ('criticism', 1), ('cure', 1), ('dans', 1), ('deal', 1), ('decide', 1), ('declare', 1), ('decline', 1), ('defend', 1), ('degree', 1), ('degreesare', 1), ('delles', 1), ('demonstrative', 1), ('denies', 1), ('dependency', 1), ('depends', 1), ('deprive', 1), ('derive', 1), ('descartes', 1), ('deserve', 1), ('designer', 1), ('desire', 1), ('destroyed', 1), ('detail', 1), ('determination', 1), ('detract', 1), ('devoid', 1), ('differently', 1), ('difficulty', 1), ('diminish', 1), ('direction', 1), ('disagree', 1), ('disapproval', 1), ('discussingwhere', 1), ('dispositionsdoing', 1), ('dispute', 1), ('distinguishable', 1), ('divinity', 1), ('divisionandsubdivision', 1), ('doca', 1), ('doctrine', 1), ('dodge', 1), ('dog', 1), ('domicilium', 1), ('dominion', 1), ('donc', 1), ('door', 1), ('doubt', 1), ('driven', 1), ('due', 1), ('dynamic', 1), ('earthly', 1), ('easily', 1), ('east', 1), ('eclipse', 1), ('elasticity', 1), ('election', 1), ('element', 1), ('elsewhere', 1), ('embody', 1), ('emphasizes', 1), ('enable', 1), ('enclose', 1), ('encodingutf', 1), ('endures', 1), ('energy', 1), ('energysource', 1), ('englishman', 1), ('enormous', 1), ('ensue', 1), ('entity', 1), ('equates', 1), ('equilibrium', 1), ('erroneous', 1), ('essence', 1), ('establishes', 1), ('ether', 1), ('everyday', 1), ('evidently', 1), ('eviter', 1), ('exceed', 1), ('existenceare', 1), ('expect', 1), ('explains', 1), ('express', 1), ('falseqed', 1), ('fanciful', 1), ('fantasy', 1), ('fast', 1), ('february', 1), ('few', 1), ('fictional', 1), ('figurewhich', 1), ('fire', 1), ('firstshove', 1), ('footnote', 1), ('foreseen', 1), ('foresightand', 1), ('formation', 1), ('foundation', 1), ('frame', 1), ('free', 1), ('fuller', 1), ('function', 1), ('gabble', 1), ('generate', 1), ('generation', 1), ('generator', 1), ('gentleman', 1), ('gift', 1), ('gland', 1), ('godcontinually', 1), ('godgiven', 1), ('godhas', 1), ('govern', 1), ('grace', 1), ('gravitation', 1), ('greatness', 1), ('ground', 1), ('grow', 1), ('half', 1), ('hang', 1), ('headon', 1), ('heard', 1), ('heavenly', 1), ('heavy', 1), ('herrenhausen', 1), ('hinders', 1), ('hobbes', 1), ('hope', 1), ('hors', 1), ('horse', 1), ('hypothesisthe', 1), ('ignorance', 1), ('ignorant', 1), ('illusion', 1), ('illustrates', 1), ('imaginatively', 1), ('imbalance', 1), ('impetus', 1), ('impiety', 1), ('important', 1), ('impossibility', 1), ('impulsive', 1), ('incompatible', 1), ('inconsistent', 1), ('inconvenience', 1), ('incorporeal', 1), ('independently', 1), ('indicates', 1), ('indifference', 1), ('indifferentness', 1), ('indiscernibles', 1), ('inelastic', 1), ('inert', 1), ('inevitably', 1), ('infer', 1), ('inference', 1), ('infers', 1), ('infiniteis', 1), ('infinitesimal', 1), ('informal', 1), ('informally', 1), ('input', 1), ('inquiry', 1), ('insist', 1), ('intangible', 1), ('interact', 1), ('interfere', 1), ('interferencewithout', 1), ('intermediary', 1), ('interpretation', 1), ('interrelation', 1), ('intervene', 1), ('intimately', 1), ('introduce', 1), ('invent', 1), ('irregular', 1), ('issue', 1), ('itincluding', 1), ('itis', 1), ('itthe', 1), ('january', 1), ('jolt', 1), ('jurieu', 1), ('justifies', 1), ('kept', 1), ('label', 1), ('lament', 1), ('largely', 1), ('largeness', 1), ('latin', 1), ('least', 1), ('leaveswithout', 1), ('leibnizclarke', 1), ('leur', 1), ('liable', 1), ('lie', 1), ('light', 1), ('likely', 1), ('lion', 1), ('liquid', 1), ('literal', 1), ('live', 1), ('livelyminded', 1), ('locationofmatter', 1), ('lockedup', 1), ('longevity', 1), ('loose', 1), ('loss', 1), ('lossofforce', 1), ('lovely', 1), ('low', 1), ('lusage', 1), ('machinemaker', 1), ('machinenamely', 1), ('machinesas', 1), ('madness', 1), ('magnitude', 1), ('maintains', 1), ('majesty', 1), ('malebranche', 1), ('mark', 1), ('materialistsa', 1), ('mathematician', 1), ('mathematicsi', 1), ('mathematicsie', 1), ('matterandvacuum', 1), ('matterones', 1), ('matterrays', 1), ('me', 1), ('meansindeed', 1), ('measurability', 1), ('mechanically', 1), ('mechanism', 1), ('mediate', 1), ('medium', 1), ('mention', 1), ('mercury', 1), ('merit', 1), ('microscope', 1), ('milk', 1), ('mine', 1), ('miraclea', 1), ('miss', 1), ('mistaken', 1), ('misuse', 1), ('modern', 1), ('monster', 1), ('monstrous', 1), ('motionlessness', 1), ('motionsthis', 1), ('motive', 1), ('movableness', 1), ('mundana', 1), ('mundane', 1), ('nail', 1), ('naturalit', 1), ('nest', 1), ('newtonian', 1), ('none', 1), ('nota', 1), ('notice', 1), ('nowhere', 1), ('objection', 1), ('oblige', 1), ('obliges', 1), ('observe', 1), ('obstruct', 1), ('obstruction', 1), ('occasion', 1), ('occupy', 1), ('odd', 1), ('oftener', 1), ('omnipotent', 1), ('omniscient', 1), ('open', 1), ('operating', 1), ('opportunity', 1), ('ordinary', 1), ('ordre', 1), ('organlike', 1), ('originate', 1), ('otherwiseacknowledging', 1), ('otherwisewe', 1), ('outsideis', 1), ('oversight', 1), ('paid', 1), ('pan', 1), ('paragraph', 1), ('particlesthat', 1), ('partssuch', 1), ('pas', 1), ('pass', 1), ('passing', 1), ('passingson', 1), ('passiveness', 1), ('payer', 1), ('performeg', 1), ('perishable', 1), ('phenomenon', 1), ('philosophically', 1), ('philosophisant', 1), ('philosophyprinciples', 1), ('phoenician', 1), ('physic', 1), ('pineal', 1), ('placewhich', 1), ('plan', 1), ('plant', 1), ('plato', 1), ('plea', 1), ('plenty', 1), ('pointsit', 1), ('possibility', 1), ('postscript', 1), ('postulate', 1), ('powerfully', 1), ('powerthings', 1), ('praise', 1), ('predetermine', 1), ('prefer', 1), ('preferable', 1), ('preservation', 1), ('preserver', 1), ('presume', 1), ('presupposes', 1), ('pretty', 1), ('prevents', 1), ('primarily', 1), ('principe', 1), ('principlethat', 1), ('proceed', 1), ('prodigy', 1), ('prompt', 1), ('propertysomething', 1), ('proportional', 1), ('proposition', 1), ('provision', 1), ('pumped', 1), ('pumpedout', 1), ('pure', 1), ('purpose', 1), ('push', 1), ('pythagoras', 1), ('que', 1), ('query', 1), ('qui', 1), ('quip', 1), ('raise', 1), ('random', 1), ('rapport', 1), ('rarer', 1), ('reader', 1), ('realmit', 1), ('reapplying', 1), ('reasonably', 1), ('reasoning', 1), ('reasonwhich', 1), ('recently', 1), ('receu', 1), ('recourir', 1), ('recourse', 1), ('reductio', 1), ('refer', 1), ('reflect', 1), ('refusal', 1), ('refute', 1), ('regularity', 1), ('relates', 1), ('relationship', 1), ('relief', 1), ('remain', 1), ('remembers', 1), ('remotest', 1), ('replace', 1), ('report', 1), ('represent', 1), ('representatif', 1), ('restore', 1), ('result', 1), ('retain', 1), ('rewind', 1), ('rhyme', 1), ('rid', 1), ('righthas', 1), ('rigorous', 1), ('rigorously', 1), ('rise', 1), ('rock', 1), ('role', 1), ('sail', 1), ('samuel', 1), ('satisfactory', 1), ('satisfied', 1), ('saw', 1), ('sceptic', 1), ('scholastic', 1), ('science', 1), ('scold', 1), ('senseorgan', 1), ('sensible', 1), ('sensoria', 1), ('sensory', 1), ('separable', 1), ('settle', 1), ('sheer', 1), ('shoot', 1), ('shut', 1), ('sight', 1), ('similar', 1), ('sinking', 1), ('skillful', 1), ('slide', 1), ('slightest', 1), ('smoke', 1), ('smoothly', 1), ('somehow', 1), ('somewhat', 1), ('somewhere', 1), ('sont', 1), ('soonerlike', 1), ('sophia', 1), ('sophism', 1), ('sort', 1), ('sothere', 1), ('spacefinite', 1), ('spatiotemporal', 1), ('speak', 1), ('special', 1), ('spent', 1), ('spinoza', 1), ('spirit', 1), ('split', 1), ('splitting', 1), ('springswhose', 1), ('stage', 1), ('star', 1), ('status', 1), ('stay', 1), ('stickiness', 1), ('straighten', 1), ('straightline', 1), ('strength', 1), ('strictly', 1), ('strike', 1), ('strong', 1), ('structure', 1), ('stuffstill', 1), ('subdivision', 1), ('subtle', 1), ('succeed', 1), ('sudden', 1), ('suddenly', 1), ('suffit', 1), ('superficial', 1), ('superior', 1), ('supreme', 1), ('surpass', 1), ('surpasses', 1), ('suspect', 1), ('symmetrical', 1), ('tache', 1), ('target', 1), ('team', 1), ('temp', 1), ('temporal', 1), ('ten', 1), ('tendency', 1), ('terminate', 1), ('themby', 1), ('themeg', 1), ('theology', 1), ('thesethe', 1), ('thingie', 1), ('thinglike', 1), ('thingsie', 1), ('thingswill', 1), ('thoroughly', 1), ('thoughtfully', 1), ('tick', 1), ('tiniest', 1), ('tinker', 1), ('tiny', 1), ('title', 1), ('tolerance', 1), ('total', 1), ('touch', 1), ('truth', 1), ('ubiquity', 1), ('unaltered', 1), ('unbounded', 1), ('undergo', 1), ('uninterrupted', 1), ('unites', 1), ('universal', 1), ('universeremaining', 1), ('ununited', 1), ('unusualness', 1), ('upshot', 1), ('us', 1), ('usualnessunusualness', 1), ('utterly', 1), ('vacuumas', 1), ('variety', 1), ('vastly', 1), ('versa', 1), ('version', 1), ('vice', 1), ('violates', 1), ('virtually', 1), ('wander', 1), ('watchmaker', 1), ('watchprovided', 1), ('waterexactly', 1), ('weak', 1), ('weakness', 1), ('weighty', 1), ('west', 1), ('whatsoever', 1), ('wheel', 1), ('whenever', 1), ('wherever', 1), ('wholly', 1), ('whyit', 1), ('wide', 1), ('wisely', 1), ('working', 1), ('worldsee', 1), ('worldthe', 1), ('worship', 1), ('writes', 1), ('writing', 1), ('xml', 1), ('yes', 1), ('yield', 1)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGI1N_P7-v7q"
      },
      "source": [
        "# **STEP 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkrAeGFdWSqg"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "from heapq import nlargest\n",
        "from nltk.tag import pos_tag\n",
        "from string import punctuation\n",
        "from inspect import getsourcefile\n",
        "from collections import defaultdict\n",
        "from nltk.tokenize import word_tokenize\n",
        "from os.path import abspath, join, dirname\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRsVCCTdWYIZ"
      },
      "source": [
        "# Create a list with all the relations of each noun "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npwXTFTkWVE4"
      },
      "source": [
        "def relation_list(nouns):\n",
        "\n",
        "    relation_list = defaultdict(list)\n",
        "    \n",
        "    for k in range (len(nouns)):   \n",
        "        relation = []\n",
        "        for syn in wordnet.synsets(nouns[k], pos = wordnet.NOUN):\n",
        "            for l in syn.lemmas():\n",
        "                relation.append(l.name())\n",
        "                if l.antonyms():\n",
        "                    relation.append(l.antonyms()[0].name())\n",
        "            for l in syn.hyponyms():\n",
        "                if l.hyponyms():\n",
        "                    relation.append(l.hyponyms()[0].name().split('.')[0])\n",
        "            for l in syn.hypernyms():\n",
        "                if l.hypernyms():\n",
        "                    relation.append(l.hypernyms()[0].name().split('.')[0])\n",
        "        relation_list[nouns[k]].append(relation)\n",
        "    return relation_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRV1Zx-iWiqd"
      },
      "source": [
        "# Compute the lexical chain between each noun and their relation and apply a threshold of similarity between each word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy7z5vG5Wv1c"
      },
      "source": [
        "def create_lexical_chain(nouns, relation_list):\n",
        "    lexical = []\n",
        "    threshold = 0.5\n",
        "    for noun in nouns:\n",
        "        flag = 0\n",
        "        for j in range(len(lexical)):\n",
        "            if flag == 0:\n",
        "                for key in list(lexical[j]):\n",
        "                    if key == noun and flag == 0:\n",
        "                        lexical[j][noun] +=1\n",
        "                        flag = 1\n",
        "                    elif key in relation_list[noun][0] and flag == 0:\n",
        "                        syns1 = wordnet.synsets(key, pos = wordnet.NOUN)\n",
        "                        syns2 = wordnet.synsets(noun, pos = wordnet.NOUN)\n",
        "                        if syns1[0].wup_similarity(syns2[0]) >= threshold:\n",
        "                            lexical[j][noun] = 1\n",
        "                            flag = 1\n",
        "                    elif noun in relation_list[key][0] and flag == 0:\n",
        "                        syns1 = wordnet.synsets(key, pos = wordnet.NOUN)\n",
        "                        syns2 = wordnet.synsets(noun, pos = wordnet.NOUN)\n",
        "                        if syns1[0].wup_similarity(syns2[0]) >= threshold:\n",
        "                            lexical[j][noun] = 1\n",
        "                            flag = 1\n",
        "        if flag == 0: \n",
        "            dic_nuevo = {}\n",
        "            dic_nuevo[noun] = 1\n",
        "            lexical.append(dic_nuevo)\n",
        "            flag = 1\n",
        "    return lexical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWIGeDWMW1a0"
      },
      "source": [
        "# Prune the lexical chain, deleting the chains that are more weak with just a few words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XC6en23W-ao"
      },
      "source": [
        "def prune(lexical):\n",
        "    final_chain = []\n",
        "    while lexical:\n",
        "        result = lexical.pop()\n",
        "        if len(result.keys()) == 1:\n",
        "            for value in result.values():\n",
        "                if value != 1: \n",
        "                    final_chain.append(result)\n",
        "        else:\n",
        "            final_chain.append(result)\n",
        "    return final_chain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQjCXhUkXEHA"
      },
      "source": [
        "# Class for finding lexical_chains in the letters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTbERxOm-00t",
        "outputId": "5656174b-1d21-4295-98c7-5d97480465be"
      },
      "source": [
        "\"\"\"\n",
        "Class for summarize the text: \n",
        "    Input:\n",
        "        text: The input text that we have read.\n",
        "        lexical_chain: The final lexical chain with the most important\n",
        "        n: The number of sentence we want our summary to have. \n",
        "    Output:\n",
        "        The lexical_chains.\n",
        "\"\"\"\n",
        "class Summarizer:\n",
        "    \n",
        "    def __init__(self, threshold_min=0.1, threshold_max=0.9):\n",
        "        self.threshold_min = threshold_min\n",
        "        self.threshold_max = threshold_max \n",
        "        self._stopwords = set(stopwords.words('english') + list(punctuation ,'utterance','ref','genid','clarke','thing'))\n",
        "        \n",
        "        \n",
        "    \"\"\" \n",
        "      Compute the frequency of each of word taking into account the \n",
        "      lexical chain and the frequency of other words in the same chain. \n",
        "      Normalize and filter the frequencies. \n",
        "    \"\"\"\n",
        "    def return_frequencies(self, words, lexical_chain):\n",
        "        frequencies = defaultdict(int)\n",
        "        for word in words:\n",
        "            for w in word:\n",
        "                if w not in self._stopwords:\n",
        "                    flag = 0\n",
        "                    for i in lexical_chain:\n",
        "                        if w in list(i.keys()):\n",
        "                            frequencies[w] = sum(list(i.values()))\n",
        "                            flag = 1\n",
        "                            break\n",
        "                    if flag == 0: \n",
        "                        frequencies[w] += 1\n",
        "        m = float(max(frequencies.values()))\n",
        "        for w in list(frequencies.keys()):\n",
        "            frequencies[w] = frequencies[w]/m\n",
        "            if frequencies[w] >= self.threshold_max or frequencies[w] <= self.threshold_min:\n",
        "                del frequencies[w]\n",
        "        return frequencies\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    \"\"\"\n",
        "    Read the letters.\n",
        "    \"\"\"\n",
        "    in_txt = join(dirname(abspath(getsourcefile(lambda:0))) , \"/content/Leibniz-Clarke Letters.xml\")\n",
        "    with open(in_txt, \"r\", encoding=\"utf-8\" ) as f:\n",
        "        input_txt = f.read() \n",
        "        f.close()\n",
        "        \n",
        "    \"\"\"\n",
        "    Return the nouns of the entire text.\n",
        "    \"\"\"\n",
        "    position = ['NN', 'NNS', 'NNP', 'NNPS']\n",
        "    \n",
        "    sentence = nltk.sent_tokenize(input_txt)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = [tokenizer.tokenize(w) for w in sentence]\n",
        "    tagged =[pos_tag(tok) for tok in tokens]\n",
        "    nouns = [word.lower() for i in range(len(tagged)) for word, pos in tagged[i] if pos in position ]\n",
        "        \n",
        "    relation = relation_list(nouns)\n",
        "    lexical = create_lexical_chain(nouns, relation)\n",
        "    final_chain = prune(lexical)\n",
        "    \"\"\"\n",
        "    Print the lexical chain. \n",
        "    \"\"\"   \n",
        "    for i in range(len(final_chain)):\n",
        "        print(\"Chain \"+ str(i+1) + \" : \" + str(final_chain[i]))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chain 1 : {'mixture': 2}\n",
            "Chain 2 : {'moyen': 2}\n",
            "Chain 3 : {'vulgar': 2}\n",
            "Chain 4 : {'collision': 1, 'collisions': 1}\n",
            "Chain 5 : {'mechanics': 3}\n",
            "Chain 6 : {'impact': 2}\n",
            "Chain 7 : {'cubes': 2}\n",
            "Chain 8 : {'ship': 3}\n",
            "Chain 9 : {'finites': 2}\n",
            "Chain 10 : {'limits': 2}\n",
            "Chain 11 : {'jar': 2}\n",
            "Chain 12 : {'aren': 2}\n",
            "Chain 13 : {'subdivision': 2}\n",
            "Chain 14 : {'divisions': 1, 'division': 1}\n",
            "Chain 15 : {'lip': 2}\n",
            "Chain 16 : {'angel': 2}\n",
            "Chain 17 : {'birth': 1, 'births': 1}\n",
            "Chain 18 : {'adversaries': 2}\n",
            "Chain 19 : {'qu': 2}\n",
            "Chain 20 : {'par': 2}\n",
            "Chain 21 : {'loss': 2}\n",
            "Chain 22 : {'generator': 2}\n",
            "Chain 23 : {'hors': 2}\n",
            "Chain 24 : {'principe': 2}\n",
            "Chain 25 : {'union': 3}\n",
            "Chain 26 : {'descartes': 3}\n",
            "Chain 27 : {'philosophical': 2}\n",
            "Chain 28 : {'sooner': 2}\n",
            "Chain 29 : {'chimeras': 1, 'monster': 1, 'imagination': 1}\n",
            "Chain 30 : {'absurdity': 2}\n",
            "Chain 31 : {'names': 2}\n",
            "Chain 32 : {'drops': 3, 'drop': 1}\n",
            "Chain 33 : {'leaves': 3}\n",
            "Chain 34 : {'garden': 2}\n",
            "Chain 35 : {'princess': 2}\n",
            "Chain 36 : {'pair': 2}\n",
            "Chain 37 : {'occurs': 2}\n",
            "Chain 38 : {'motive': 1, 'motives': 1}\n",
            "Chain 39 : {'june': 2}\n",
            "Chain 40 : {'discussion': 3}\n",
            "Chain 41 : {'intelligentia': 2}\n",
            "Chain 42 : {'dependency': 1, 'dependence': 1}\n",
            "Chain 43 : {'connections': 1, 'link': 1}\n",
            "Chain 44 : {'virtue': 2, 'merits': 1}\n",
            "Chain 45 : {'scapula': 4}\n",
            "Chain 46 : {'imperfection': 2, 'perfection': 1, 'perfections': 1, 'flaws': 1, 'defect': 1, 'flaw': 1}\n",
            "Chain 47 : {'agent': 7, 'agents': 1}\n",
            "Chain 48 : {'uniformity': 2}\n",
            "Chain 49 : {'dimensions': 2}\n",
            "Chain 50 : {'ages': 2}\n",
            "Chain 51 : {'millions': 2}\n",
            "Chain 52 : {'line': 4, 'lines': 1}\n",
            "Chain 53 : {'partition': 2}\n",
            "Chain 54 : {'problem': 4}\n",
            "Chain 55 : {'think': 2, 'consideration': 1, 'thinks': 1}\n",
            "Chain 56 : {'largeness': 2}\n",
            "Chain 57 : {'term': 3}\n",
            "Chain 58 : {'kinds': 2, 'sort': 1}\n",
            "Chain 59 : {'mean': 3}\n",
            "Chain 60 : {'distance': 3}\n",
            "Chain 61 : {'b': 3}\n",
            "Chain 62 : {'expression': 1, 'appearance': 1, 'look': 1}\n",
            "Chain 63 : {'options': 2, 'option': 1}\n",
            "Chain 64 : {'indifferent': 5}\n",
            "Chain 65 : {'attraction': 2}\n",
            "Chain 66 : {'tangent': 2}\n",
            "Chain 67 : {'hasn': 2}\n",
            "Chain 68 : {'theologians': 2}\n",
            "Chain 69 : {'does': 2}\n",
            "Chain 70 : {'shove': 2}\n",
            "Chain 71 : {'sentence': 3}\n",
            "Chain 72 : {'operation': 4}\n",
            "Chain 73 : {'essence': 3}\n",
            "Chain 74 : {'dictionary': 3, 'dictionaries': 1}\n",
            "Chain 75 : {'goclenius': 7}\n",
            "Chain 76 : {'lessening': 2}\n",
            "Chain 77 : {'necessity': 10}\n",
            "Chain 78 : {'choosing': 2}\n",
            "Chain 79 : {'choice': 9, 'choices': 1}\n",
            "Chain 80 : {'year': 2, 'years': 1}\n",
            "Chain 81 : {'arise': 2}\n",
            "Chain 82 : {'eme': 2}\n",
            "Chain 83 : {'degrees': 2, 'level': 1}\n",
            "Chain 84 : {'d': 2}\n",
            "Chain 85 : {'differ': 4}\n",
            "Chain 86 : {'implies': 2}\n",
            "Chain 87 : {'axiom': 3}\n",
            "Chain 88 : {'section': 2, 'text': 1}\n",
            "Chain 89 : {'number': 3}\n",
            "Chain 90 : {'successions': 1, 'succession': 1}\n",
            "Chain 91 : {'times': 6}\n",
            "Chain 92 : {'grow': 2}\n",
            "Chain 93 : {'tribe': 2}\n",
            "Chain 94 : {'bacon': 2}\n",
            "Chain 95 : {'idol': 2, 'idols': 1}\n",
            "Chain 96 : {'demonstrations': 2, 'demonstration': 1, 'resistance': 1}\n",
            "Chain 97 : {'numbers': 1, 'act': 1, 'options': 1, 'writings': 1}\n",
            "Chain 98 : {'concern': 2, 'concerns': 1}\n",
            "Chain 99 : {'scholium': 2, 'note': 1}\n",
            "Chain 100 : {'general': 2}\n",
            "Chain 101 : {'principia': 2}\n",
            "Chain 102 : {'omnipresence': 3}\n",
            "Chain 103 : {'command': 2}\n",
            "Chain 104 : {'quot': 5}\n",
            "Chain 105 : {'lord': 3}\n",
            "Chain 106 : {'paragraph': 3}\n",
            "Chain 107 : {'disorder': 2, 'disorders': 1}\n",
            "Chain 108 : {'terms': 7}\n",
            "Chain 109 : {'context': 2}\n",
            "Chain 110 : {'amendment': 3}\n",
            "Chain 111 : {'outset': 4}\n",
            "Chain 112 : {'finite': 2}\n",
            "Chain 113 : {'imply': 5}\n",
            "Chain 114 : {'living': 4}\n",
            "Chain 115 : {'couldn': 3}\n",
            "Chain 116 : {'etc': 4}\n",
            "Chain 117 : {'argument': 5}\n",
            "Chain 118 : {'scope': 2}\n",
            "Chain 119 : {'vacuum': 7, 'void': 1}\n",
            "Chain 120 : {'greeks': 2}\n",
            "Chain 121 : {'thesis': 5}\n",
            "Chain 122 : {'latin': 4}\n",
            "Chain 123 : {'fatality': 5}\n",
            "Chain 124 : {'words': 8}\n",
            "Chain 125 : {'bits': 1, 'moment': 1, 'bit': 1}\n",
            "Chain 126 : {'sun': 4}\n",
            "Chain 127 : {'constitution': 4}\n",
            "Chain 128 : {'show': 1, 'shows': 1}\n",
            "Chain 129 : {'reply': 2, 'answer': 1, 'answers': 1}\n",
            "Chain 130 : {'supramundana': 4}\n",
            "Chain 131 : {'hypothesis': 6, 'supposition': 1}\n",
            "Chain 132 : {'dispositions': 3}\n",
            "Chain 133 : {'topic': 3, 'subjects': 1, 'subject': 1}\n",
            "Chain 134 : {'day': 2}\n",
            "Chain 135 : {'socinians': 2}\n",
            "Chain 136 : {'foresight': 2}\n",
            "Chain 137 : {'divine': 3}\n",
            "Chain 138 : {'beauty': 2}\n",
            "Chain 139 : {'pre': 2}\n",
            "Chain 140 : {'harmony': 3}\n",
            "Chain 141 : {'advance': 4}\n",
            "Chain 142 : {'remedy': 1, 'remedies': 1}\n",
            "Chain 143 : {'otherwise': 2}\n",
            "Chain 144 : {'length': 1, 'longevity': 1, 'extension': 1, 'duration': 1}\n",
            "Chain 145 : {'credit': 1, 'mention': 1, 'statement': 1, 'definitions': 1, 'argument': 1, 'notice': 1, 'answers': 1, 'fiction': 1, 'definition': 1, 'reference': 1, 'fictions': 1, 'assertion': 1, 'comment': 1, 'arguments': 1, 'answer': 1, 'remarks': 1, 'postscript': 1, 'replies': 1}\n",
            "Chain 146 : {'one': 3, 'ones': 1}\n",
            "Chain 147 : {'gift': 1, 'grants': 1}\n",
            "Chain 148 : {'workman': 5}\n",
            "Chain 149 : {'watch': 7}\n",
            "Chain 150 : {'excellence': 2, 'majesty': 1}\n",
            "Chain 151 : {'materials': 2, 'material': 1}\n",
            "Chain 152 : {'influence': 6}\n",
            "Chain 153 : {'correspondence': 2}\n",
            "Chain 154 : {'point': 5}\n",
            "Chain 155 : {'story': 2, 'reports': 1}\n",
            "Chain 156 : {'trouble': 2}\n",
            "Chain 157 : {'size': 9, 'immensity': 1, 'sizes': 1}\n",
            "Chain 158 : {'isn': 12}\n",
            "Chain 159 : {'y': 6}\n",
            "Chain 160 : {'x': 8}\n",
            "Chain 161 : {'translates': 2}\n",
            "Chain 162 : {'opportunity': 1, 'chance': 1}\n",
            "Chain 163 : {'depend': 4}\n",
            "Chain 164 : {'metaphysics': 4}\n",
            "Chain 165 : {'existence': 11, 'beings': 1}\n",
            "Chain 166 : {'suppose': 5}\n",
            "Chain 167 : {'equilibrium': 1, 'balance': 1, 'imbalance': 1, 'situation': 1}\n",
            "Chain 168 : {'archimedes': 2}\n",
            "Chain 169 : {'i': 3}\n",
            "Chain 170 : {'a': 9}\n",
            "Chain 171 : {'proposition': 1, 'premise': 1}\n",
            "Chain 172 : {'identity': 2}\n",
            "Chain 173 : {'mathematics': 6, 'geometry': 1}\n",
            "Chain 174 : {'manner': 1, 'way': 1}\n",
            "Chain 175 : {'theodicy': 3}\n",
            "Chain 176 : {'book': 2, 'works': 1, 'workings': 1, 'plants': 1}\n",
            "Chain 177 : {'knowledge': 3}\n",
            "Chain 178 : {'phrase': 13}\n",
            "Chain 179 : {'admixture': 1, 'status': 1, 'level': 1, 'lack': 1}\n",
            "Chain 180 : {'physics': 3}\n",
            "Chain 181 : {'epicurus': 3}\n",
            "Chain 182 : {'democritus': 2}\n",
            "Chain 183 : {'difference': 2}\n",
            "Chain 184 : {'reason': 64, 'reasons': 1}\n",
            "Chain 185 : {'effect': 9, 'consequence': 1, 'consequences': 1, 'upshot': 1, 'result': 1}\n",
            "Chain 186 : {'governor': 5}\n",
            "Chain 187 : {'course': 2}\n",
            "Chain 188 : {'reality': 8}\n",
            "Chain 189 : {'kingdom': 5, 'realm': 1}\n",
            "Chain 190 : {'creator': 2}\n",
            "Chain 191 : {'eternity': 10, 'infinity': 1}\n",
            "Chain 192 : {'everything': 23}\n",
            "Chain 193 : {'philosopher': 2, 'philosophers': 1}\n",
            "Chain 194 : {'presence': 9}\n",
            "Chain 195 : {'nerves': 2}\n",
            "Chain 196 : {'species': 3}\n",
            "Chain 197 : {'animals': 3}\n",
            "Chain 198 : {'passage': 4}\n",
            "Chain 199 : {'government': 5}\n",
            "Chain 200 : {'providence': 4}\n",
            "Chain 201 : {'intelligence': 4}\n",
            "Chain 202 : {'mundane': 2}\n",
            "Chain 203 : {'fate': 2}\n",
            "Chain 204 : {'materialism': 2}\n",
            "Chain 205 : {'clock': 6}\n",
            "Chain 206 : {'something': 36}\n",
            "Chain 207 : {'glory': 2}\n",
            "Chain 208 : {'regulation': 3}\n",
            "Chain 209 : {'ways': 3}\n",
            "Chain 210 : {'set': 3, 'sets': 1}\n",
            "Chain 211 : {'springs': 3}\n",
            "Chain 212 : {'weights': 10}\n",
            "Chain 213 : {'skill': 3, 'science': 1, 'physics': 1}\n",
            "Chain 214 : {'counterparts': 3}\n",
            "Chain 215 : {'meanings': 1, 'meaning': 1}\n",
            "Chain 216 : {'omnipresent': 3}\n",
            "Chain 217 : {'sensorium': 25}\n",
            "Chain 218 : {'places': 7, 'place': 1, 'region': 1, 'parts': 1, 'position': 1, 'state': 1, 'locations': 1, 'west': 1, 'states': 1, 'centre': 1, 'regions': 1, 'end': 1}\n",
            "Chain 219 : {'organs': 3}\n",
            "Chain 220 : {'case': 5, 'cause': 1, 'question': 1}\n",
            "Chain 221 : {'whereas': 4}\n",
            "Chain 222 : {'sees': 3, 'see': 1}\n",
            "Chain 223 : {'means': 10}\n",
            "Chain 224 : {'brain': 11, 'head': 1}\n",
            "Chain 225 : {'images': 6}\n",
            "Chain 226 : {'pictures': 6}\n",
            "Chain 227 : {'mind': 3}\n",
            "Chain 228 : {'comparison': 4}\n",
            "Chain 229 : {'anything': 31}\n",
            "Chain 230 : {'help': 3}\n",
            "Chain 231 : {'present': 4}\n",
            "Chain 232 : {'doesn': 27}\n",
            "Chain 233 : {'errors': 1, 'error': 1, 'fault': 1, 'faults': 1}\n",
            "Chain 234 : {'nothing': 34}\n",
            "Chain 235 : {'enemies': 2}\n",
            "Chain 236 : {'principles': 4, 'thinking': 1}\n",
            "Chain 237 : {'philosophy': 15, 'doctrine': 1}\n",
            "Chain 238 : {'anyone': 6}\n",
            "Chain 239 : {'grace': 1, 'goodness': 1, 'advantage': 1}\n",
            "Chain 240 : {'miracles': 5, 'miracle': 1}\n",
            "Chain 241 : {'nature': 12}\n",
            "Chain 242 : {'laws': 6}\n",
            "Chain 243 : {'accordance': 3}\n",
            "Chain 244 : {'thing': 35, 'needs': 1, 'need': 1, 'absence': 1, 'presence': 1}\n",
            "Chain 245 : {'energy': 2, 'light': 1}\n",
            "Chain 246 : {'force': 16, 'power': 1, 'forces': 1, 'powers': 1, 'ability': 1, 'abilities': 1, 'strength': 1, 'weakness': 1}\n",
            "Chain 247 : {'amount': 3}\n",
            "Chain 248 : {'clockmaker': 4}\n",
            "Chain 249 : {'intervention': 3, 'work': 1, 'creation': 1, 'design': 1, 'designs': 1}\n",
            "Chain 250 : {'machine': 22, 'machines': 1}\n",
            "Chain 251 : {'motion': 32, 'motions': 1, 'figures': 1, 'figure': 1}\n",
            "Chain 252 : {'re': 2}\n",
            "Chain 253 : {'universe': 2, 'world': 1}\n",
            "Chain 254 : {'workmanship': 4}\n",
            "Chain 255 : {'opinion': 3, 'view': 1, 'notion': 1, 'sensing': 1, 'perception': 1, 'conceptions': 1, 'absolute': 1, 'kind': 1, 'kinds': 1}\n",
            "Chain 256 : {'tie': 2}\n",
            "Chain 257 : {'time': 47}\n",
            "Chain 258 : {'usage': 2, 'activity': 1, 'action': 1, 'course': 1, 'care': 1, 'work': 1, 'order': 1, 'exercise': 1, 'orders': 1, 'movements': 1, 'cause': 1, 'issues': 1, 'difficulties': 1, 'pass': 1, 'preservation': 1, 'election': 1, 'move': 1, 'operations': 1, 'use': 1, 'difficulty': 1, 'recourse': 1, 'walk': 1, 'service': 1, 'creation': 1, 'determination': 1, 'help': 1, 'role': 1, 'continuance': 1}\n",
            "Chain 259 : {'word': 6, 'part': 1, 'name': 1, 'particles': 1, 'plural': 1}\n",
            "Chain 260 : {'fact': 2, 'regard': 1}\n",
            "Chain 261 : {'passivity': 1, 'passiveness': 1}\n",
            "Chain 262 : {'implication': 1, 'idea': 1, 'reasoning': 1, 'mind': 1, 'attending': 1, 'principles': 1, 'principle': 1, 'facts': 1, 'fact': 1, 'thinking': 1, 'example': 1, 'minds': 1, 'whole': 1, 'ideas': 1, 'attributes': 1, 'notions': 1, 'case': 1, 'evidence': 1, 'possibility': 1, 'question': 1, 'inference': 1, 'events': 1, 'rule': 1, 'questions': 1, 'reasonings': 1, 'issue': 1, 'proof': 1, 'inquiries': 1, 'proofs': 1}\n",
            "Chain 263 : {'shouldn': 3}\n",
            "Chain 264 : {'page': 43, 'pages': 1}\n",
            "Chain 265 : {'apos': 88}\n",
            "Chain 266 : {'verb': 3}\n",
            "Chain 267 : {'perceives': 2}\n",
            "Chain 268 : {'t': 71}\n",
            "Chain 269 : {'things': 127}\n",
            "Chain 270 : {'organ': 10, 'eye': 1}\n",
            "Chain 271 : {'sense': 9, 'wisdom': 1, 'sensation': 1, 'senses': 1}\n",
            "Chain 272 : {'space': 149, 'shape': 1, 'extent': 1, 'infinite': 1, 'curve': 1, 'stretch': 1, 'spaces': 1, 'stretches': 1, 'shapes': 1, 'infinites': 1, 'pores': 1}\n",
            "Chain 273 : {'newton': 29}\n",
            "Chain 274 : {'followers': 3}\n",
            "Chain 275 : {'locke': 3}\n",
            "Chain 276 : {'e': 10}\n",
            "Chain 277 : {'god': 216, 'divinity': 1, 'representation': 1, 'attribute': 1, 'point': 1, 'conclusion': 1, 'illusion': 1, 'idea': 1, 'wisdom': 1, 'thoughts': 1, 'thought': 1, 'whole': 1, 'points': 1, 'plan': 1, 'fact': 1, 'distinction': 1, 'example': 1, 'case': 1, 'cause': 1, 'question': 1, 'mind': 1, 'sense': 1, 'images': 1, 'questions': 1, 'opinions': 1, 'cases': 1, 'event': 1, 'miracle': 1, 'notion': 1, 'principle': 1, 'principles': 1, 'opinion': 1, 'rules': 1, 'respect': 1, 'fantasy': 1, 'movement': 1, 'change': 1, 'beginning': 1, 'pattern': 1, 'errors': 1, 'advance': 1, 'passage': 1, 'sensation': 1, 'interpretation': 1, 'ideas': 1, 'representations': 1, 'view': 1, 'events': 1, 'show': 1, 'miracles': 1, 'beginnings': 1, 'minds': 1, 'fate': 1, 'thinking': 1, 'stop': 1, 'offers': 1, 'touch': 1, 'senses': 1, 'causes': 1, 'movements': 1, 'action': 1, 'move': 1, 'actions': 1, 'optics': 1, 'query': 1, 'rule': 1, 'truth': 1, 'concept': 1, 'regard': 1}\n",
            "Chain 278 : {'others': 5}\n",
            "Chain 279 : {'matter': 77, 'affairs': 1, 'matters': 1}\n",
            "Chain 280 : {'people': 8}\n",
            "Chain 281 : {'england': 2}\n",
            "Chain 282 : {'religion': 2}\n",
            "Chain 283 : {'ref': 227}\n",
            "Chain 284 : {'utterance': 294}\n",
            "Chain 285 : {'november': 2}\n",
            "Chain 286 : {'paper': 8, 'substance': 1, 'n': 1, 'relation': 1, 'way': 1, 'differences': 1, 'relations': 1, 'difference': 1, 'entity': 1, 'tolerance': 1, 'objects': 1, 'quantity': 1, 'manner': 1, 'ether': 1, 'nature': 1, 'i': 1, 'particle': 1, 'particles': 1, 'contradiction': 1, 'basis': 1, 'property': 1, 'word': 1, 'properties': 1, 'quantities': 1, 'part': 1, 'amount': 1, 'water': 1, 'air': 1, 'atoms': 1, 'substances': 1, 'p': 1, 'form': 1, 'name': 1, 'items': 1, 'rapport': 1, 'chronology': 1, 'effects': 1, 'corpuscle': 1, 'atom': 1, 'proportion': 1, 'ratio': 1, 'movable': 1, 'stuff': 1, 'fluid': 1, 'contrast': 1, 'rest': 1, 'length': 1, 'duration': 1, 'material': 1, 'item': 1, 'amounts': 1}\n",
            "Chain 287 : {'s': 68}\n",
            "Chain 288 : {'nr': 7}\n",
            "Chain 289 : {'turn': 16}\n",
            "Chain 290 : {'g': 4}\n",
            "Chain 291 : {'papers': 2}\n",
            "Chain 292 : {'clarke': 104}\n",
            "Chain 293 : {'leibniz': 71}\n",
            "Chain 294 : {'participants': 2, 'person': 1, 'body': 1, 'natural': 1, 'souls': 1, 'soul': 1, 'cognate': 1, 'materialists': 1, 'bodies': 1, 'man': 1, 'humans': 1, 'maker': 1, 'source': 1, 'author': 1, 'world': 1, 'king': 1, 'someone': 1, 'mathematicians': 1, 'reader': 1, 'friends': 1, 'cartesians': 1, 'designer': 1, 'system': 1, 'runners': 1, 'newtonians': 1, 'planets': 1, 'root': 1, 'men': 1, 'horses': 1, 'universe': 1, 'human': 1, 'don': 1, 'earth': 1, 'servants': 1, 'gentlemen': 1, 'creatures': 1, 'stars': 1, 'location': 1, 'object': 1, 'writer': 1, 'writers': 1, 'place': 1, 'animal': 1, 'sources': 1, 'individuals': 1, 'friend': 1, 'parts': 1, 'state': 1, 'epicurean': 1, 'representative': 1, 'temps': 1, 'position': 1, 'places': 1, 'animals': 1, 'boy': 1, 'rock': 1, 'bottom': 1, 'payers': 1, 'region': 1, 'sides': 1, 'locations': 1, 'side': 1, 'systems': 1, 'end': 1, 'cognates': 1}\n",
            "Chain 295 : {'dialog': 2}\n",
            "Chain 296 : {'version': 1, 'explanation': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}